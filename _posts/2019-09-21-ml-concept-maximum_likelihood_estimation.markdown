---
layout: post
title: MLE(Maximum Likelihood Estimation)와 MAP(Maxim A Posterior)에 관하여
date: 2019-09-16 00:00:00
img: gan/gan.png
categories: [gan-concept] 
tags: [MLE, ML, Maximum likelihood estimation] # add tag
---

### **Reference**

<br>

- http://sanghyukchun.github.io/58/
- http://rstudio-pubs-static.s3.amazonaws.com/204928_c2d6c62565b74a4987e935f756badfba.html
- http://arkainoh.blogspot.com/2017/10/parametric.learning.maximum.likelihood.estimation.html

<br>

- 이번 글에서는 GAN을 시작하기에 앞서서 필수적인 통계적 개념을 다루려고 합니다.
- 통계학 및 머신러닝 전반적으로 아주 중요한 개념인 MLE(Maximum Likelihood Estimation)와 MAP(Maximum A Posterior)에 대하여 다루어 보겠습니다.
- 제 블로그의 [다른 글](https://gaussian37.github.io/ml-concept-mle-and-map/)을 참조하셔도 충분합니다. 

<br>

- 이 글에서 다룰 내용
- 확률밀도함수(PDF: Probability Density Function)
- 가능도(Likelihood) : 특정 사건이 일어날 가능성
- 사건이 여러 번 발생할 경우의 가능도
- 최대우도추정(MLE: Maximum Likelihood Estimation)
- MLE 예시
- 최대 사후 확률 추정(MAP: Maximum A Posterior)
- Bayes Theory

<br>

### **확률밀도함수(PDF: Probability Density Function)**

<br>

- 먼저 확률밀도함수의 정의를 알기 위하여 아래 두가지 예제를 통하여 `확률`에 대하여 먼저 알아보도록 하겠습니다.
- 주사위를 예를 들어 보겠습니다. 주사위를 던져서 나올 수 있는 숫자는 1, 2, 3, 4, 5, 6이고 각 숫자가 나올 확률은 1/6 으로 모두 같습니다.
- 또 다른 예로 동전을 10번 던져서 앞면은 0 ~ 10번 나올 수 있으며 각각의 확률을 계산해 보면 각각 0.001, 0.01, 0.044, 0.117, 0.205, 0.246, 0.205, 0.117, 0.044, 0.01, 0.001 인 경우를 생각해 보겠습니다.
- 두 경우 모두 일어날 수 있는 사건이 6개, 11개로 정해져 있으며 각각에 대한 확률을 구할 수 있고 확률의 합은 1이 됩니다.

<br>
<center><img src="../assets/img/gan/concept/mle_and_map/1.png" alt="Drawing" style="width: 800px;"/></center>
<br>

- 이번에는 1에서 6 사이의 숫자 중 랜덤으로 아무 숫자나 뽑는다고 가정해 보겠습니다.
- 이 때 정확히 5가 뽑힐 확률은 얼마일까? 1과 6사이에는 무한개의 숫자가 있으니 정확히 5가 뽑힐 확률은 1/∞=0 입니다.
    - 이렇게 `연속적인 구간`에서는 어떤 특정 숫자가 뽑힐 확률은 전부 0이됩니다.
    - 이는 연속된 숫자 사이에서 뽑을 수 있는 숫자의 갯수가 무한하기 때문입니다.
- 따라서 이런 연속사건인 경우 특정 숫자가 나올 확률을 말하는 것은 의미가 없어 다른 방법을 생각해야 하는데, 숫자가 `특정 구간에 속할 확률`을 말하는 것이 그 대안이 될 수 있습니다.
    - 여기서 **특정 구간에 속할 확률**을 구하는 것이 즉, `확률밀도함수(Probability Density Function, PDF)`를 구하는 것 입니다.
- 참고로 위 그림과 같이 `이산적인 구간`에서는 어떤 특정 숫자에 해당하는 확률이 실제 확률을 뜻하고 발생 가능한 숫자들의 확률을 모두 더하면 1이 됩니다.
    - 이와 같이 이산적인 구간에서 어떤 특정 숫자에 해당하는 확률을 `확률질량함수(Probability Mass Function)`이라고 합니다.

<br>

- 앞의 예시의 1에서 6사이의 숫자를 뽑는 상황을 다시 생각해 보겠습니다.
- 1에서 6사이의 숫자 중 정확히 5가 뽑힐 확률은 0이지만 4에서 5사이의 숫자가 뽑힐 확률은 20%입니다.
    - 전체 구간의 길이는 6 - 1 = 5이고 4에서 5사이 구간의 길이는 1이기 때문입니다.
- 이처럼 우리는 특정 사건에 대한 확률 대신 특정 구간에 속할 확률을 구함으로서 간접적으로 특정 사건의 확률에 대한 감을 잡을 수 있습니다.
- 이것을 설명하는 곡선이 **확률밀도함수(Probability Density Function: PDF)** 입니다.
- **PDF**는 특정 구간에 속할 확률을 계산하기 위한 함수이며 **그래프에서 특정 구간에 속한 넓이=특정 구간에 속할 확률**이 되게끔 정한 함수입니다.

<br>
<center><img src="../assets/img/gan/concept/mle_and_map/2.png" alt="Drawing" style="width: 800px;"/></center>
<br>

- 위 그림으로 예를 들어 살펴 보겠습니다. 왼쪽의 그림에서 `PDF`의 값은 1에서 6사이에서는 전부 0.2이고 나머지 구간에서는 전부 0인데, 이는 1에서 6사이의 숫자를 뽑는 상황을 그림으로 나타낸 것입니다.
- 1보다 작거나 6보다 큰 숫자를 뽑을 수는 없으므로 이에 해당하는 확률밀도함수의 함수의 $$ y $$값은 전부 0이고, 1~6사이에서는 무작위로 숫자를 뽑으므로 $$ y $$값은 전부 0.2로 같습니다.
- 전체 확률은 1이므로 그림의 직사각형의 넓이는 1이되고 $$ y $$값은 전부 0.2가 되며, 이를 바탕으로 2에서 4사이의 숫자가 뽑힐 확률을 계산하면 2×0.2=0.42×0.2=0.4로 40%가 됩니다. 
- 오른쪽 그래프는 정규분포(Normal distribution)이며, 가장 흔히 쓰이는 평균 0, 분산 1인 표준정규분포(Standard normal distribution)를 나타냅니다.
- 표준정규분포의 `PDF`는 정규분포식의 구간을 구하면 되는데, 연속 구간에서 영역을 구해야 하므로 적분을 통하여 구할 수 있습니다.
    - 정규분포식 $$ f(x) = \frac{1}{sqrt{2 \pi \sigma^{2}}} exp(\frac{-(x-m)^{2}}{2\sigma^{2}}) $$ 입니다.
- 정규분포의 적분 과정은 다소 복잡하니 표준정규분포 케이스를 통하여 대략적으로 보면 $$ z = (x - m) / \sigma $$의 범위가 -1.96 ~ 1.96이면 95%임이 알려져 있습니다.

<br>

- 정리하면 연속사건의 경우에는 특정 사건이 일어날 확률은 모두 0이며, 어떤 구간에 속할 확률은 `PDF`를 이용해서 구할 수 있습니다.
- 그러면 특정 사건에 대한 해석은 할 수 없는 것일까요? 단순히 할 수 없다 라고 말하기 보다는 다음과 같이 해석해 보는 것도 좋을 것 같습니다.
- 위의 정규분포의 경우를 보면 0이 나올 확률도 0, 1이 나올 확률도 0, 999가 나올 확률도 0으로 모두 같으므로 0, 1, 999가 나올 가능성은 전혀 차이가 없다고 말해야 하지만 정규분포의 그림을 보고 알 수 있드시 표준정규분포에서 가장 위로 솟아올라 있는 0 근처가 나올 가능성이 가장 높고, 1 근처가 나올 가능성은 그보다 낮으며, 999같이 큰 수가 나올 가능성은 거의 없습니다.
- 그러나 **확률이라는 지표로는 이런 연속사건간의 가능성 차이를 표시할 수가 없다는 문제**가 있습니다.

<br>

### **가능도(Likelihood) : 특정 사건이 일어날 가능성**

<br>

- 설명한 대로 **연속사건에서는 특정 사건이 일어날 확률이 전부 0으로 계산**되기 때문에 사건들이 **일어날 가능성을 비교하는 것이 불가능**하며, 가능도라는 개념을 적용해야 이를 비교할 수 있습니다.
- 가능도란 쉽게 말하자면 위에 있는 그래프들에서 $$ y $$값이라고 생각하면 됩니다.
- **$$ y $$값이 높을수록 일어날 가능성이 높은 사건**입니다. 주사위나 동전을 던지는 경우와 같은 **이산확률분포**에서는 $$ y $$값이 각 사건이 일어날 확률을 나타내었으므로 **가능도=확률**이 되어, 확률이 높을수록 일어날 가능성이 높은 사건이 됩니다.
- 반면, 정규분포같이 연속확률분포인 경우는 `PDF`의 값이 바로 $$ y $$가 되며 0에 해당하는 `PDF`값이 0.4로 1에 해당하는 `PDF`값인 0.24보다 높아 0 근처의 숫자가 나올 `가능성`이 1 근처의 숫자가 나올 `가능성`보다 높다고 할 수 있습니다.
- 하지만 0이 나올 `확률`과 1이 나올 `확률`은 모두 0입니다. 이를 정리하면 가능도의 직관적인 정의는 다음과 같습니다.
- 가능도의 직관적인 정의 : 확률분포함수의 $$ y $$ 값
    - 이산확률분포: **가능도 = 확률**
    - 연속확률분포: 가능도 ≠ 확률, **가능도=PDF**

<br>

### **사건이 여러 번 발생할 경우의 가능도**

<br>

- 이번에는 사건이 여러 번 일어날 경우를 생각해 보겠습니다.
- **첫번째 케이스**는 주사위를 3번 던져 각각 1, 3, 6이 나올 확률을 확인하는 문제입니다.
    - 주사위를 던져 1, 3, 6이 나올 확률은 모두 1/6 입니다.
    - 따라서 3번 던져 각각 1, 3, 6이 나올 확률은 (1/6) x (1/6) x (1/6) = 1/216이 됩니다.
- **두번째 케이스**는 동전을 10번 던지는 일을 3회 시행하여 각 시행에서 앞면이 각각 2, 5, 7번 나올 확률을 확인하는 문제입니다.
    - 이항확률 분포를 따르게 되므로 확률은 각각 0.044, 0.246, 0.117입니다. 
    - 따라서 동전을 10번 던져서 각각 2, 5, 7번이 나올 확률은 0.044 x 0.246 x 0.177 = 0.001입니다.
- 가능도도 마찬가지입니다. 앞서 셀 수 있는 사건에서는 확률과 가능도가 같다고 했으므로 주사위를 3번 던져 각각 1, 3, 6 이 나올 가능성을 나타내는 가능도는 1/216입니다.
- 동전을 던지는 경우의 가능도도 마찬가지로 확률과 같은 0.001이 됩니다.

<br>

- 이제 연속사건이 여러 번 일어날 경우를 살펴보자. 앞서 언급한 평균 0, 분산 1인 정규분포에서 숫자를 3번 뽑았을 때 차례대로 -1, 0, 1이 나올 확률은 각각의 사건이 일어날 확률이 모두 0이므로 결국 0이 됩니다.
- 그러나 가능도의 경우 -1, 1이 나올 가능도는 0.24, 0이 나올 가능도는 0.4이므로 -1, 0, 1이 나올 가능도는 0.24 × 0.4 × 0.24 = 0.02가 되어 확률과는 다른 값으로 나타나게 됩니다.

<br>

### **최대우도추정(MLE: Maximum Likelihood Estimation)**

<br>

- 앞에서 배운 가능도(Likelihood) 개념을 중심으로 `최대우도추정(MLE: Maximum Likelihood Estimation)`에 대하여 다루어 보려고 합니다.
- 먼저 `MLE`는 random variable의 파라미터를 estimate하는 방법 중 하나인데, 오직 주어진 관측값 또는 데이터를 토대로 파라미터를 estimation 합니다.
    - 예를 들어, p의 확률로 앞면이 나오고 1-p의 확률로 뒷면이 나오는 동전을 던져서 p를 예측한다고 가정해 보겠습니다.
    - MLE로 p를 계산하기 위해서는 간단하게 앞면이 나온 횟수를 전체 횟수로 나누면 됩니다.
- 보다 더 자세한 설명을 위해 알려지지 않은 probability density function $$ f_{0} $$이 있다고 하고 $$ X = (x_{1}, x_{2}, ... , x_{n}) $$를 그 확률로 생성되는 관측값이라고 가정해보겠습니다.
- density function이 $$ \theta $$로 parameterize된 어떤 분포라고 하고 데이터 $$ x $$가 주어진다면, $$ \theta $$의 값을 알 수 있을 때, $$ f(x \vert \theta) $$의 값을 계산할 수 있습니다.
- 만약 $$ f $$가 가우시안 이라면 $$ \theta $$는 평균인 $$ \mu $$와 분산인 $$ \Sigma $$일 것이고, 베르누이라면 $$ 0 \ge p \ge 1 $$가 될 것입니다.
- 이렇게 정의하면 가능도는 다음과 같이 정의할 수 있습니다.

<br>

$$ L(\theta; x_{1}, x_{2}, ... , x_{n}) = L(\theta; X) = f(X \vert \theta) = f(x_{1}, x_{2}, ..., x_{n} \vert \theta) $$

<br>

- Maximum Likelihood Estimation (MLE)는 $$ \theta $$를 estimate하는 방법 중 하나로 Likelihood를 최대로 만드는 값으로 선택하는 것입니다.
- 만약 선택하는 값을 $$ \hat{\theta} $$라고 적는다면, MLE는 다음과 같은 방식으로 값을 찾습니다.

<br>

$$ \hat{\theta} = argmax_{\theta} L(\theta; X) = argmax_{\theta} f(X \vert \theta) $$

<br>
       
- 만약 관측값들이 `i.i.d(independent and identical distributed)`라면 $$ f(X \vert \theta) = \prod_{i}f(x_{i} \vert \theta) $$가 되며, 여기에 $$ log $$를 씌우면 덧셈 꼴이 됩니다.
- 이 때, $$ log $$는 단조증가함수이므로, $$ log $$를 취했을 때 최대값을 가지는 지점과 원래 최대값을 가지는 지점이 동일하고 곱셈보다 덧셈이 계산이 더 간편하므로 많은 경우에 **likelihood**를 사용하기 보다는 **log likelihood**를 사용하여 파라미터 estimation을 계산합니다.
- `MLE`는 가장 간단한 파라미터 estimation 방법이지만, 관측값에 따라 그 값이 너무 민감하게 변한다는 단점이 있습니다. 
    - 예를 들어 동전 던지기의 극단적인 경우로 n번 던져서 n번 앞면이 나오는 경우 likelihood를 1이라고 하면 합리적일까요? 

<br>

### **MLE 예시**

<br>

- 먼저 위에서 설명한 `MLE`를 예시를 통하여 자세하게 알아보도록 하겠습니다.
- **첫번째 예 : 모양이 일그러진 동전**
- 어떤 동전의 모양이 많이 일그러져 있으면 앞이 나올 확률을 0.5라고 말할 수 없고, 실제로 던져봐야 그 확률을 알 수 있습니다.
- 실제로 1000번을 던져봤더니 앞이 400번, 뒤가 600번이 나왔다면 동전을 던져서 앞이 나올 확률 `p`가 대략 얼마 정도라고 봐야할까요?
- 대부분 0.4 정도라고 생각할 것이며 이것은 `p`의 `MLE` 값과 일치합니다. 다시 정리하면 **동전을 1000번 던져 앞이 400번 나올 가능성을 최대로 하는 `p`는 0.4**라는 뜻이며 수식을 이용한 증명은 다음과 같습니다.
    - 먼저 이 시행은 베르누이 분포를 따르고 앞면이 나올 확률이 `p`라면 $$ L =  _{100}C_{4} p^{400}(1-p)^{600} $$ 입니다.
    - 그러면 언제 $$ L $$이 최대가 되는지 알아보아야 합니다. $$ L $$이 최대가 되는 지점의 미분값은 0이므로 미분값이 0이 되는 지점의 `p`값을 울프람 알파로 구해보겠습니다.
    
<br>
<center><img src="../assets/img/gan/concept/mle_and_map/3.png" alt="Drawing" style="width: 800px;"/></center>
<br>         

- **두번째 예 : 키 측정 하기**
- 만약 나의 키를 오차가 있는 측정기로 여러번 재었는데 178cm, 179cm, 180cm, 181cm, 182cm 로 나왔다고 가정해 보겠습니다.
- 이렇게 여러번 측정했을 때, 가장 가능성이 높은 것은 180cm라고 생각하는 것이 합리적일 수 있는데 왜 그런지 한번 살펴보겠습니다.
- 보통 이런 센서를 통한 관측값은 **참 값을 평균으로 하는 가우시안 분포**를 가집니다. 그러면 어떤 참 값이라고 하는 값을 평균으로 보고 그 값을 기준으로 분산 만큼 데이터가 퍼져있을 것입니다.
- 가우시안 분포 기준으로 참 값이 $$ \mu $$ 이고 분산은 $$ \sigma^{2} $$ 이므로 측정값이 $$ x $$ 일 때, 가능도 $$ y $$는 $$ \frac{1}{sqrt{2\pi}\sigma}exp(-\frac{(x - \mu)^{2}}{2\sigma^{2}}) $$가 됩니다.
- 따라서 5번 측정한 키가 178cm, 179cm, 180cm, 181cm, 182cm로 나올 가능도 $$ L $$은 각각의 값이 나올 가능도의 곱과 같습니다.

<br>

따라서 $$ L = \frac{1}{sqrt{2\pi}\sigma}exp(-\frac{(178 - \mu)^{2}}{2\sigma^{2}}) \times \frac{1}{sqrt{2\pi}\sigma}exp(-\frac{(179 - \mu)^{2}}{2\sigma^{2}}) \times \frac{1}{sqrt{2\pi}\sigma}exp(-\frac{(180 - \mu)^{2}}{2\sigma^{2}}) \times \frac{1}{sqrt{2\pi}\sigma}exp(-\frac{(181 - \mu)^{2}}{2\sigma^{2}}) \times \frac{1}{sqrt{2\pi}\sigma}exp(-\frac{(182 - \mu)^{2}}{2\sigma^{2}}) $$

<br>

- 이 때, $$ L $$이 최대가 된다는 것은 $$ exp(-\frac{(178 - \mu)^{2}}{2\sigma^{2}})exp(-\frac{(179 - \mu)^{2}}{2\sigma^{2}})exp(-\frac{(180 - \mu)^{2}}{2\sigma^{2}})exp(-\frac{(181 - \mu)^{2}}{2\sigma^{2}})exp(-\frac{(182 - \mu)^{2}}{2\sigma^{2}}) = exp((\frac{-( (178 - \mu)^{2} + (179 - \mu)^{2} + (180 - \mu)^{2} + (181 - \mu)^{2} + (182 - \mu)^{2} )}{2\sigma^{2}}) $$ 가 최대가 된다는 뜻입니다.
- 다시 정리하면 $$ (178 - \mu)^{2} + (179 - \mu)^{2} + (180 - \mu)^{2} + (181 - \mu)^{2} + (182 - \mu)^{2} ) $$가 최소가 되어야 한다는 것이거 이는 $$ \mu = 180 $$일 때 입니다.
- 따라서 $$ \mu = 180 $$일 때, $$ L $$이 최대가 되는 MLE를 찾을 수 있습니다.

<br>

- 두가지 예제를 비교해보면 평균값이 최대 가능도일 것이라는 우리의 추측이 일치하는 것을 수학적으로 확인할 수 있었습니다.

<br>

### **최대 사후 확률 추정(MAP: Maximum A Posterior)**

<br>

- 위에서 설명한 바와 같이 `MLE`는 측정한 데이터 값에 큰 영향을 받게 되는 문제가 있음을 확인하였습니다. 편향된 데이터가 들어온다면 편향된 `MLE`를 얻을 수 밖에 없습니다.
- `MLE`의 단점을 개선하기 위하여  `MAP(Maximum A Posterior)`를 사용하기도 합니다.
- 이 방법은 $$ \theta $$가 주어지고 그 $$ \theta $$에 대한 데이터들의 확률 또는 가능도를 최대화하는 `MLE`와는 달리 **주어진 데이터에 대해 최대 확률을 가지는 $$ \theta $$를 찾습니다.**
- `MLE`: $$ \theta $$가 주어져 있고 이 때, 데이터가 들어오면 가능도를 계산합니다. 이 가능도가 최대가 되는 $$ \theta $$를 이용하는 것이 `MLE`입니다.
    - 가우시안 분포를 예로 들면 가능도를 계산하기 위한 $$ \mu, \sigma $$가 주어져 있고 이 때, 데이터가 들어오면 가능도를 계산합니다.
    - 그러면 여러가지 $$ \mu, \sigma $$의 케이스가 있는데 각각의 데이터들의 가능도를 계산하고 모든 가능도의 곱이 최대가 되는 최대 가능도의 $$ \mu, \sigma $$를 찾아서 파라미터로 가지고 있어야 합니다. 
- `MAP`: 주어진 데이터에 대해 최대 확률을 가지는 $$ \theta $$를 찾는것입니다. 즉 $$ \theta $$의 확률이라는 개념이 들어옵니다.
    - 여러 파라미터들 중에서 지금까지 관측된 **데이터를 기준**으로 가장 확률이 높은 $$ \theta $$를 찾는 것이 목표이고 그런 $$ \theta $$를 찾을 수 있다면 좀 더 general한 추론을 할 수 있는 결과를 만들어낼 수 있습니다.
    - 앞의 `MLE`에서는 극단적인 예시로 동전을 던져서 앞면만 계속 나왔다고 하면 likelihood를 이용하기 때문에 앞면이 나올 확률만 극단적으로 높게 선택하게됩니다.
    - 하지만 `MAP`에서는 어떤 $$ \theta $$가 나올 확률이 높을까? 라는 질문을 통하여 `MLE`와 같이 극단적으로 추론을 하지는 않게 됩니다.
- 하지만 아쉽게도 우리가 직접적으로 구할 수 있는 것은 $$ f(X \vert \theta) $$ 즉, 주어진  함수와 그 함수에 사용되는 $$ \theta $$가 있을 때, 데이터 $$ X $$의 가능도입니다. 즉 직접적으로 데이터에 대한 $$ \theta $$가 발생할 확률을 구할 수는 없습니다.
    - 이 때 사용하는 것이 `Bayes Theory`입니다.

<br>

### **Bayes Theory**

<br>

- 베이즈 이론은 $$ p(Y \vert X) $$와 $$ p(X \vert Y) $$의 관계를 표현하는 식입니다. 

<br>

$$ p(Y \vert X) = \frac{ p(X \vert Y) p(Y)}{p(X)} $$

<br>

- 앞에서 다룬 $$ f(X \vert \theta) $$는 `likelihood`였습니다. 여기서 추가할 개념으로 $$ f(\theta) $$는 `prior`라는 것이고 $$ f(\theta \vert X) $$는 앞에서 다룬것 처럼 `posterior` 입니다.
- 우리가 직접 구할 수 있는 것은 `likelihood`이고 likelihood의 단점을 개선하기 위해서 구하고 싶은것이 `posterior` 즉, 데이터에 대한 $$ \theta $$의 확률입니다.
- 새로 등장한 `prior`는 **데이터와 상관없이** 현재 알고 있는 $$ \theta $$에 대한 확률입니다. (`prior`와 비굑하면 `posterior`는 데이터가 주어졌을 때의 $$ \theta $$에 대한 확률입니다.) 
- 위의 베이즈 식을 보면 알 수 있겠지만 `posterior`는 `likelihood`와 `prior`를 통하여 구할 수 있습니다. 여기서 `likelihood`와 `posterior` 모두 최대가 되도록 하는 `\theta`를 선택해야 하는것이므로 `argmax`를 붙여 식을 다음과 같이 전개해보겠습니다.

<br>

$$ \hat{\theta} = argmax_{\theta} f(\theta \vert X) = argmax_{\theta} \frac{f(X \vert \theta) f(\theta) }{ f(X) } = argmax_{\theta} \frac{ L(\theta; X) f(\theta) }{f(X)} = argmax_{\theta} L(\theta; X) f(\theta) $$

<br>

- 위 식에서 마지막 전개는 $$ f(X) $$가 $$ \theta $$에 영향을 주지 않으므로 등식이 성립하게 됩니다.
- 따라서 $$ argmax_{\theta} $$를 하는 경우에 $$ f(\theta \vert X) = L(\theta; X)f(\theta) $$가 됨을 알 수 있습니다. 아주 중요합니다!
- 즉, `posterior`와 `likelihood`의 관계는 `prior`가 어떤 영향을 미치는 지에 따라서 같아질수도 있고 달라질수도 있다는 뜻입니다.
- 먼저 `posterior`와 `likelihood`가 같은 경우부터 살펴보면 `prior` 즉, $$ \theta $$에 대한 확률이 어떤 $$ \theta $$에도 상관없이 특정한 상수값을 가질 때 입니다. 즉 unifom distribution 을 가지는 경우라고 볼 수 있습니다.
- 반면에 $$ \theta $$에 대한 확률이 일정하지 않는 다면 `likelihood`와 `posterior`의 값은 달라집니다. $$ \theta $$에 대한 확률이 커질수록 `posterior`도 커집니다. 즉 비례관계를 가집니다.
    - 이것은 흔히 사람들이 말하는 선입견과 비슷합니다. 기존에 가지고 있는 확률이므로 현재 관측된 데이터와도 무관하기 때문입니다. 다소 주관적이거나 비논리적인 확률일 수도 있습니다. (인종, 출신, 성분에 따라 확률이 더 높다던지 등등)
- 다시 정리해보면 우리가 구하고 싶은 `posterior`는 데이터가 관측되었을 때, 그 데이터에 대한 $$ \theta $$의 확률이고 `MAP`는 `posterior` 중에서 가장 큰 값을 뜻합니다.
- 그리고`posteriror`는 `likelihood`와 `prior`의 곱에 비례합니다. 따라서 `MAP`는 `MLE`와 `prior`의 곱에 비례하다고 할 수 있습니다.

<br>
<center><img src="../assets/img/gan/concept/mle_and_map/4.png" alt="Drawing" style="width: 800px;"/></center>
<br>
- 출처: 패턴인식(오일석)       

<br>

- 이 글에서 말하고자 하는 바는 데이터와 `MLE`와 `MAP` 라는 방법을 통하여 모델에 사용되는 파라미터 $$ \theta $$를 구할 수 있고 `MAP`가 좀 더 강건한 모델이라는 것입니다.
- `MLE`에서는 **관측된 데이터만**을 이용하여 가능도를 계산하고 전체 가능도들의 곱이 최대가 되도록 해야 합니다. 
- 바꾸어 말하면 관측된 데이터의 가능도만 최대가 되도록 만족시키면 되므로 관측된 데이터 이외의 값은 관심이 없습니다.
- `MAP`에서는 관심 영역이 관측된 데이터에 대한 $$ \theta $$가 발생할 확률 값이고 물론 데이터에 크게 영향을 받지만 가능도와 같이 100% 관측된 데이터로만 계산되는 것이 아니기 때문에 편향된 데이터에 대하여 보상할 수 있는 여지가 있습니다.
    - 여기서 보상할 수 있다는 여지가 바로 `prior`입니다. 편향된 데이터가 입력되었다 하더라도 올바른 `prior`가 곱해지면 `MAP`에서는 개선이 될 수 있습니다.

  
