---
layout: post
title: Mathematics for machine learning 글 목록
date: 2000-01-01 00:00:00
img: math/mfml/mfml.jpg
categories: [math-mfml] 
tags: [코세라, coursera, mathemacis for machine learning] # add tag
---

<br>

- Imperial College London에서 제공하는 머신 러닝을 위한 수학 강의 입니다.
- 전체적으로 선형대수학과 미분적분에 대하여 다루고 있으며 마지막에 PCA를 다룹니다. 강의 내용은 상당히 좋다고 느꼈습니다.
- Specialization이므로 강의 내용과 과제가 조금 많습니다. 그것만 이겨낸다면 상당히 얻는게 많을 것이라 생각됩니다.

<br>
<center><img src="../assets/img/certification/imperial_college_mfml.png" alt="Drawing" style="width: 800px;"/></center>
<br>

## **Linear algebra**

<br>

- [Finding the size of a vector, its angle and projection](https://gaussian37.github.io/math-mfml-1/)
- [Changing the reference frame](https://gaussian37.github.io/ml-la-Changing-the-reference-frame/)
- [Operation on vectors](https://gaussian37.github.io/ml-la-Operation-on-vectors/)
- [Determinants and inverse](https://gaussian37.github.io/ml-la-Determinants-and-inverse/)
- [Eienstein summation convention](https://gaussian37.github.io/math-la-einstein_summation_convention/)
- [Symmetry of dot product](https://gaussian37.github.io/math-la-symmetry_of_dot_product/)
- [Matrices transform into the new basis vector set](https://gaussian37.github.io/math-la-matrices_transform_into_the_new_basis_vector_set/)
- [Orthogonal matrix](https://gaussian37.github.io/math-la-orthogonal_matrix/)
- [Gram schimidt process](https://gaussian37.github.io/math-la-gram_schmidt_process/)
- [Reflecting in a plane](https://gaussian37.github.io/math-la-reflecting_in_a_plane/)
- [Eigen-Things](https://gaussian37.github.io/math-mfml-eigenthings/)

<br>

## **Multivariate calculus**

<br>

- [calculus 기초](https://gaussian37.github.io/math-mfml-basic_calculus)
- [multivariate calculus와 jacobian](https://gaussian37.github.io/math-mfml-multivariate_calculus_and_jacobian/)
- [multivariate chain rule과 applications](https://gaussian37.github.io/math-mfml-multivariate_chain_rule_and_applications/)
- [Taylor series 와 linearisation](https://gaussian37.github.io/math-mfml-taylor_series_and_linearisation/)
- [Intro to Optimisation (newton-raphson method, gradient descent, lagrange multipliers)](https://gaussian37.github.io/math-mfml-intro_to_optimisation/)
- [Regression (linear regression, non-linear least squares)]((https://gaussian37.github.io/math-mfml-regression/))

<br>

## **Principal Component Analysis**

<br>

- [statistics of dataset]()
- [inner product]()
- [orthonal projection]()
- [principal component analysis]()


