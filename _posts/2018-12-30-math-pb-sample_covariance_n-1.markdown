---
layout: post
title: 표본분산에서 n-1로 나누어 주는 이유
date: 2018-12-30 00:00:00
img: math/pb/probability.jpg
categories: [math-pb] 
tags: [interview, datascience, sample covariance, n-1] # add tag
---

- **표본 분산을 구할 때 왜 n-1로 나누는가**에 대하여 알아보도록 하겠습니다.
- 먼저 다음 예제를 살펴보도록 하겠습니다.

<br>
<center><img src="../assets/img/math/pb/sample_covariance_n-1/1.png" alt="Drawing" style="width: 800px;"/></center>
<br>

- 위 데이터는 정규 분포에서 $$ N(50, 15^{2}) $$ 를 따르는 분포에서 샘플링 한 것입니다.
- 크기가 30인 표본을 임의로 추출을 하여 이 표본의 분산을 구할 때, 30으로 나눈 것과 29로 나눈것을 비교하였습니다.
- 모분산이 225이므로 30으로 나눈 것 보다 29로 나누어서 분산이 더 커지도록 하는 것이 더 적합해 보입니다. 왜 그럴까요?

<br>

---

- 정답은 `표분분산의 평균이 모분산과 같아져야 하기 때문` 입니다.
- 일단 정답을 이끌어 내기 전에 차근차근 한번 설명을 쭉 한 다음에 다시 정리해 보는 순서를 가져보려고 합니다. 그러면 기본적인 개념부터 한번씩 다시 짚어가면서 설명해 보겠습니다.

<br>

## **목차**

<br>

- ### 1. 평균과 분산
- ### 2. 모평균과 모분산
- ### 3. 표본평균의 평균과 표본평균의 분산
- ### 4. 표본평균과 `표분분산`
- ### 5. 표본분산에서 분모가 `n-1`인 이유

입니다. 3번을 4번보다 먼저 보는 이유는 우리의 목적이 `표본분산`에 있기 때문입니다.

<br>

## **1. 평균과 분산**

<br>

+ 평균은 $$ E(X) = m $$ 이고 분산은 $$ V(X) = E(X-m)^{2} $$ 입니다.
+ 그렇다면 분산은 왜 변량에서 `평균`을 뺀 값을 제곱할까요? 
    + 평균을 빼는 이유
        + 예를 들어 $$ f(x) = E(X - x)^{2} $$ 라고 하면 x = m 일 때 최솟값을 가집니다.
            + 왜냐하면 $$ E(X^{2} - 2xX + x^{2}) = E(X^{2}) -2xE(X) + x^{2} $$ 이고
            + 완전 제곱식/미분을 이용하면 $$ x = E(X) = m $$ 일 때 `최솟값`을 가짐을 알 수 있습니다.
        + 평균을 이용하는 것이 변량(데이터)들의 분포를 측정할 수 있는 고유한 값(최솟값)이 되고 **평균과 변량들의 분포를 연관**지을 수 있음
    + 제곱을 하는 이유
        + 모든 값을 양수로 만들어서 편차의 합이 줄어드는 것을 막기 위함
            + 이 경우는 절대값을 취해줘도 만족을 함
        + 편차의 큰 경우 더 편차를 크게 만들어 페널티를 주기 위함
        
<br><br>
        
## **2. 모평균과 모분산**

<br>

+ 모평균 : m
+ 모분산 : $$ \sigma^{2} $$
+ 모평균과 모분산은 정해진 `상수`이고, 중요한 것은 `모른다` 입니다. 현실적으로 알 수 없는 값입니다.
    + 대통령 선거가 딱 끝난 시점 또는 수능 시험이 딱 끝난 시점에는 모평균과 모분산이 정해집니다. **즉, 상수 라는 뜻** 입니다.
    + 딱 끝난 시점에는 전체 데이터가 너무 많으므로 모든 것을 고려할 수 없습니다. **모평균과 모분산은 모른다는 뜻**입니다.

<br><br>

## **3. 표본평균의 평균과 표본평균의 분산**

<br>

+ 모집단에서 선택한 표본들을 평균낸것을 `표본평균` $$ \bar{X} $$ 라고 하겠습니다.
    + 그러면 `표본평균` $$ \bar{X} = X_{1}, X_{2}, ..., X_{n} $$ 으로 나타낼 수 있습니다.  
+ `표본평균의 평균`은 `표본평균`(전체 모집단에서 내가 n개 만큼 랜덤으로 꺼내서 평균)들의 평균 낸것입니다.
    + 당연히 표본 평균 각각은 모평균보다 커질수도 있고 작아질 수도 있습니다. 랜덤으로 꺼냈기 때문이지요.
    + 하지만 이것을 무한히 반복하면 어떻게 될까요? `무한히 반복해보면 모평균에 가까워` 집니다. 시뮬레이션을 해봐도 알 수 있습니다.
    + 따라서 $$ E(\bar{X} = \frac{X_{1} + X_{2} + ... + X_{n}}{n}) = m $$ 이 됩니다. 즉, **표본평균의 평균은 모평균(m)** 입니다.
+ `표본평균의 분산`은 `표본평균`들이 얼마나 산포되어 있는지에 대한 수치 입니다.
    + 따라서 $$ V(\bar{X}) = V(\frac{X_{1} + X_{2} + ... + X_{n}}{n}) = \frac{1}{n^{2}}V(X_{1} + X_{2} + ... + X_{n})$$ 로 표현할 수 있습니다.
    + 이 때, 각각의 $$ X_{1}, X_{2}, ..., X_{n} $$ 들은 연관관계가 없습니다. `충분히 큰 모집단`에서 랜덤으로 꺼냈기 때문입니다.
        + 모집단이 충분이 크다면 샘플링이 복원/비복원 모두 데이터 간 연관관계가 없다고 볼 수 있습니다.
        + 여기서 중요한 개념이 나옵니다. 한정된 집단에서는 $$ V(aX) = a^{2}V(X) $$로 알려져 있습니다.            
        + 하지만, **무한히 큰 집단에서는 표본집단간의 연관성이 없다**고 보기 때문에 $$ V(aX) = aV(X) $$ 로 봅니다.
            + 마치 나의 몸무게와 나의 수학 점수 간의 분포 처럼 연관이 없다고 볼 수 있습니다.
        + 따라서 $$ \frac{1}{n^{2}}V(X_{1} + X_{2} + ... + X_{n}) = \frac{1}{n^{2}}nV(X) = \frac{\sigma^{2}}{n} $$ 가 됩니다.        
+ 다시 정리하면 `표본평균의 평균` = m, `표본평균의 분산` = $$ \frac{\sigma^{2}}{n} $$ 입니다.
+ 표본평균의 평균은 모평균과 같지만, **표본평균의 분산** < **모분산** 이 됩니다. 모분산에 비해 표본평균의 분산은 **왜 줄어 들까요?**
    + A,B 라는 표뵨집단이 있다고 하면 A라는 표본집단은 점수가 높은 학생들만, B라는 집단은 점수가 낮은 학생들만 뽑힐 수 있을까요? 확률적으로 낮습니다.
    + 일반적으로 점수가 높은 학생/ 점수가 낮은 학생 섞여서 나오게 됩니다. 즉, 랜덤으로 뽑은 표본집단도 평균에 가까워 지게 됩니다.
        + 즉, 랜덤으로 뽑은 **표본집단의 평균이 모평균에 가까워**지기 때문에, **표본평균들 끼리 산포가 줄어**들게 되고 `표본평균의 분산`은 작아지게 됩니다.

<br><br>
                
## **4. 표본평균과 표분분산**

<br>

자 마지막으로 저희가 구하려고 하는 표본분산에 다가가 보겠습니다.

+ 표본평균 : $$ \{ X_{1}, X_{2}, ... , X_{n} \} $$ 샘플을 뽑았을 때 이 샘플들 간의 평균입니다.
    + 즉, $$ \bar{X} = \frac{X_{1} + X_{2} + ... + X_{n}}{n} $$이 됩니다. 
+ 표본분산은 표본평균을 구한 바로 그 집단에서의 분산을 구한 것입니다. 자 그러면 먼저 앞에서 설명한 `표본평균의 분산`과 `표본분산` 중 어떤 것이 클까요?
    + 정답은 `표본분산`이 더 큽니다.
    + 왜냐하면 `표본평균의 분산`은 말그대로 평균들의 분산이므로 이미 산포가 줄어든 상태인 반면, **표본평균은 랜덤으로 뽑은 날것 그대로의 분산**이기 때문입니다.
+ 이 내용을 바탕으로 저희가 아는 방식대로 `표본분산`을 구해보도록 하겠습니다.
    + 표본분산 = $$ \frac{(X_{1} - \bar{X})^{2} + (X_{2} - \bar{X})^{2} + ... + (X_{n} - \bar{X})^{2}}{n} $$ 일까요???
    + `아닙니다.` **분모가 n-1이 되어야 합니다.** 왜그럴까요??
    
<br><br>

## **5. 표본분산에서 분모가 n-1인 이유**

<br>

+ 일단 분모가 n-1이 되야 하는것에 대한 배경이 있습니다. 먼저 분모는 n인 채로 다음 두 방법으로 분산을 구해보겠습니다.
    + 표본평균 사용 : $$ \frac{(X_{1} - \bar{X})^{2} + (X_{2} - \bar{X})^{2} + ... + (X_{n} - \bar{X})^{2}}{n} $$ 
    + 모평균 사용 : $$ \frac{(X_{1} - m)^{2} + (X_{2} - m)^{2} + ... + (X_{n} - m)^{2}}{n} $$
    + 어떤 방법이 더 값이 작을까요? 정답은 `표본평균`을 사용하였을 때 입니다.
        + `1.평균과 분산`에서 보았듯이 변량들의 평균을 이용하여 분산을 구헀을 때, 값이 가장 작습니다. 반면 모평균은 사실 변량들과 직접적인 연관은 없습니다.
        + 즉 표본평균을 사용하여 표본분산을 구했을 때가 모평균을 사용하여 구했을 때 보다 값이 항상 작거나 같기 때문에, 값을 크게 해줄 필요가 있었습니다.
        + 그래서 방법중의 하나로, 분모를 작게 만들어 값을 크게 해야 하는 배경이 있었습니다.
    

+ 직관적인 이유 : 자유도
    + 표본을 뽑을 때는 `모평균` 이라는 제약조건을 가집니다. 예를 들어 전체 표본이 N개 일 때, 내가 N-1개를 뽑았다면 마지막 1개는 궁금할까요?
    + 정답은 안 궁금하다 입니다. 왜냐면 모평균을 알고 있기 때문에 추정할 수 있는 값이기 때문입니다.
    + 따라서 표본을 뽑을 때 모든 표본을 다 자유롭게 뽑는게 아니라 마지막 1개는 전혀 자유롭지 않기 때문에 n-1로 나누어 주게 됩니다.
    
+ 수식 증명 : `표분분산의 평균이 모분산과 같아져야 한다.` = $$ E(s^{2}) = \sigma^{2} $$
    + 어떤 표본집단의 분산은 모분산보다 클 수도 있고 작을 수도 있습니다. 하지만 그 `표본분산의 평균`이 모분산에 가까워져야 표본을 잘 뽑았다고 할 수 있습니다.
    + `표본분산`을 $$ s^{2} $$ 이라고 하였을 때,  $$ E(s^{2}) = \sigma^{2} $$ 가 되어야 합니다.
    + 만약 `표본분산`의 분모 = n-1 일 때 $$ E(s^{2}) = \sigma^{2} $$ 를 만족하면 분모는 n-1을 사용하는게 맞다고 할 수 있습니다.
    
$$ E(\frac{1}{n-1}\sum_{k=1}^{n}(X_{k} - \bar{X})^{2}) = \frac{1}{n-1} E(\sum_{k=1}^{n}( (X_{k} - m) + (m -\bar{X}) )^{2}) $$
$$ = \frac{1}{n-1} E(\sum_{k=1}^{n}( (X_{k}-m)^{2} + 2(X_{k}-m)(m-\bar{X}) + (m-\bar{X})^{2}))  $$

이 때, 괄호 안에 3개의 term $$ (X_{k}-m)^{2}, 2(X_{k}-m)(m-\bar{X}), (m-\bar{X})^{2})$$ 중 마지막 것 부터 먼저 보겠습니다.
+ 3번째 term :$$ E((m-\bar{X})^{2} ) $$ 에서 m은 `모평균`이고 $$ \bar{X} $$ 는 표본 평균입니다.
    + `모평균`과 `표본평균`의 차이를 제곱해서 기대값을 취한다면, `표본평균의 분산`이 나오게 되어 즉, $$ \frac{\sigma^{2}}{n} $$ 입니다.
    +  3번째 term 정리 : $$ E(\sum_{k=1}^{n}(m-\bar{X})^{2} ) = n \times \frac{\sigma^{2}}{n} = \sigma^{2} $$   
+ 2번째 term: 상수항을 앞으로 빼고 모양을 정리하기 위해 음수 하나를 밖으로 빼면 다음과 같습니다.
    + $$ E(\sum_{k=1}^{n} 2(X_{k}-m)(m-\bar{X})) = -2E((m-\bar{X})\sum_{k=1}^{n}(m-X_{k})) = -2E((m-\bar{X})(nm-n\bar{X})) = -2nE((m - \bar{X})^{2}) = -2n\frac{\sigma^{2}}{n} = -2\sigma^{2} $$
    + 2번째 term 정리 : $$ -2\sigma^{2} $$
+ 1번째 term : $$ E(\sum_{k=1}^{n}(X_{k}-m)^{2}) $$ 즉, 각 원소 $$ X_{k} $$ 에 모평균을 뺀 것에 대한 기대값 즉, 모분산의 정의에 해당합니다.
    + 기대값만 보았을 때, $$ E((X_{k}-m)^{2})\sigma^{2} $$ 이므로 전체 값 $$ E(\sum_{k=1}^{n}(X_{k}-m)^{2}) = n\sigma^{2} $$ 입니다.
    + 1번째 term 정리 : $$ n\sigma^{2} $$

마지막으로 식을 정리하면 $$ \frac{1}{n-1}(n\sigma^{2} -2\sigma^{2} + \sigma^{2}) = \sigma^{2} $$ = 모분산.

따라서 처음에 정한 가설인 표분분산의 분모가 `n-1`일 때, `표분분산의 평균이 모분산과 같아져야 한다.` 를 만족하므로 분모는 `n-1` 입니다.

<br>

+ 참조 자료 : https://www.youtube.com/watch?v=O7JEuNKzEQ4