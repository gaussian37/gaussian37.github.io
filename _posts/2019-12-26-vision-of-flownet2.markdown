---
layout: post
title: FlowNet 2.0 (Evolution of Optical Flow Estimation with Deep Networks) 알아보기
date: 2019-12-26 00:00:00
img: vision/concept/optical_flow/0.png
categories: [vision-concept] 
tags: [vision, optical flow, luckas-kanade, horn-shunk, flownet] # add tag
---

<br>

- 논문 : https://arxiv.org/abs/1612.01925
- 참조 : https://gaussian37.github.io/vision-of-flownet/
- 참조 : https://github.com/NVIDIA/flownet2-pytorch

<br>

## **목차**

<br>

- ### [Contribution](#contribution-1)
- ### [Abstract](#abstract-1)
- ### [1. Introduction](#1-introduction-1)
- ### [2. Related Work](#2-related-work-1)
- ### [3. Dataset Schedules](#3-dataset-schedules-1)
- ### [4. Stacking Networks](#4-stacking-networks-1)
- ### [5. Small Displacements](#5-small-displacements-1)
- ### [6. Experiments](#6-experiments-1)
- ### [7. Concolusion](#7-concolusion-1)
- ### [Code Review](#code-review-1)

<br>

## **Contribution**

<br>

- 이번 글에서는 **딥러닝을 이용한 옵티컬 플로우를 추정**하는 논문인 `FlowNet 2.0`을 알아보도록 하겠습니다. 이 논문은 기존의 [FlowNet](https://gaussian37.github.io/vision-of-flownet/)을 개선한 논문으로 아직 읽어보시지 않으셨다면 링크를 클릭하셔서 읽어보시길 추천드립니다.

<br>
<div style="text-align: center;">
    <iframe src="https://www.youtube.com/embed/JSzUdVBmQP4" frameborder="0" allowfullscreen="true" width="800px" height="400px"> </iframe>
</div>
<br>

- 위 영상을 통해 FlowNet 2.0의 데모 영상을 확인할 수 있습니다. FlowNet 2.0의 논문을 읽으면서 느낀 `contribution`은 다음과 같습니다.

<br>

## **Abstract**

<br>


<br>

## **1. Introduction**

<br>


<br>

## **2. Related Work**

<br>


<br>

## **3. Dataset Schedules**

<br>


<br>

## **4. Stacking Networks**

<br>


<br>

## **5. Small Displacements**

<br>


<br>

## **6. Experiments**

<br>


<br>

## **7. Concolusion**

<br>


<br>

## **Code Review**

<br>


<br>

